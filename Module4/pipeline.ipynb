{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: implemented a data ingestion solution that uses a pipeline to copy data to your lakehouse from an external source, and then uses a Spark notebook to transform the data and load it into a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://microsoftlearning.github.io/mslearn-fabric/Instructions/Labs/04-ingest-pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As parameter\n",
    "table_name = \"sales\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Read the new sales data\n",
    "df = spark.read.format(\"csv\").option(\"header\",\"true\").load(\"Files/new_data/*.csv\")\n",
    "\n",
    "## Add month and year columns\n",
    "df = df.withColumn(\"Year\", year(col(\"OrderDate\"))).withColumn(\"Month\", month(col(\"OrderDate\")))\n",
    "\n",
    "# Derive FirstName and LastName columns\n",
    "df = df.withColumn(\"FirstName\", split(col(\"CustomerName\"), \" \").getItem(0)).withColumn(\"LastName\", split(col(\"CustomerName\"), \" \").getItem(1))\n",
    "\n",
    "# Filter and reorder columns\n",
    "df = df[\"SalesOrderNumber\", \"SalesOrderLineNumber\", \"OrderDate\", \"Year\", \"Month\", \"FirstName\", \"LastName\", \"EmailAddress\", \"Item\", \"Quantity\", \"UnitPrice\", \"TaxAmount\"]\n",
    "\n",
    "# Load the data into a table\n",
    "df.write.format(\"delta\").mode(\"append\").saveAsTable(table_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
